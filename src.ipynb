{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hazm import (\n",
    "    Normalizer, word_tokenize, POSTagger,\n",
    "    Chunker, tree2brackets, Lemmatizer,\n",
    "    DependencyParser, Stemmer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "او یک ماشین خرید.\n"
     ]
    }
   ],
   "source": [
    "normalizer = Normalizer()\n",
    "lemmatizer = Lemmatizer()\n",
    "stemmer = Stemmer()\n",
    "# sentence = \"من کتابم را به علی دادم.\"\n",
    "# sentence = \"سنگ شیشه را شکست.\"\n",
    "# sentence = \"علی سیب را از درخت چید.\"\n",
    "sentence = \"او یک ماشین خرید.\"\n",
    "# sentence = \"دختر به سگ غذا داد.\"\n",
    "\n",
    "# normalize\n",
    "normalized_sentence = normalizer.normalize(sentence)\n",
    "print(normalized_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['او', 'یک', 'ماشین', 'خرید', '.']\n",
      "[('او', 'PRO'), ('یک', 'NUM'), ('ماشین', 'N'), ('خرید', 'V'), ('.', 'PUNC')]\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(sentence)\n",
    "print(tokens)\n",
    "tagger = POSTagger ( model = 'resources/postagger.model' )\n",
    "tagged = tagger.tag(word_tokenize(normalized_sentence))\n",
    "print(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[او NP] [یک ماشین NP] [خرید VP] .\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.49.1 (0)\n -->\n<!-- Title: G Pages: 1 -->\n<svg width=\"232pt\" height=\"305pt\"\n viewBox=\"0.00 0.00 232.00 305.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 301)\">\n<title>G</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-301 228,-301 228,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<text text-anchor=\"middle\" x=\"112\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\">0 (None)</text>\n</g>\n<!-- 4 -->\n<g id=\"node2\" class=\"node\">\n<title>4</title>\n<text text-anchor=\"middle\" x=\"112\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\">4 (خرید)</text>\n</g>\n<!-- 0&#45;&gt;4 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M112,-260.8C112,-249.16 112,-233.55 112,-220.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"115.5,-220.18 112,-210.18 108.5,-220.18 115.5,-220.18\"/>\n<text text-anchor=\"middle\" x=\"133.5\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\">ROOT</text>\n</g>\n<!-- 1 -->\n<g id=\"node3\" class=\"node\">\n<title>1</title>\n<text text-anchor=\"middle\" x=\"27\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">1 (او)</text>\n</g>\n<!-- 4&#45;&gt;1 -->\n<g id=\"edge3\" class=\"edge\">\n<title>4&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M94.8,-173.8C82.36,-161.36 65.36,-144.36 51.5,-130.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"53.72,-127.77 44.18,-123.18 48.77,-132.72 53.72,-127.77\"/>\n<text text-anchor=\"middle\" x=\"88\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\">SBJ</text>\n</g>\n<!-- 3 -->\n<g id=\"node5\" class=\"node\">\n<title>3</title>\n<text text-anchor=\"middle\" x=\"112\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">3 (ماشین)</text>\n</g>\n<!-- 4&#45;&gt;3 -->\n<g id=\"edge4\" class=\"edge\">\n<title>4&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M112,-173.8C112,-162.16 112,-146.55 112,-133.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"115.5,-133.18 112,-123.18 108.5,-133.18 115.5,-133.18\"/>\n<text text-anchor=\"middle\" x=\"126\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\">OBJ</text>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<text text-anchor=\"middle\" x=\"197\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">5 (.)</text>\n</g>\n<!-- 4&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>4&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M129.2,-173.8C141.64,-161.36 158.64,-144.36 172.5,-130.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"175.23,-132.72 179.82,-123.18 170.28,-127.77 175.23,-132.72\"/>\n<text text-anchor=\"middle\" x=\"182\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\">PUNC</text>\n</g>\n<!-- 2 -->\n<g id=\"node4\" class=\"node\">\n<title>2</title>\n<text text-anchor=\"middle\" x=\"112\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">2 (یک)</text>\n</g>\n<!-- 3&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>3&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M112,-86.8C112,-75.16 112,-59.55 112,-46.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"115.5,-46.18 112,-36.18 108.5,-46.18 115.5,-46.18\"/>\n<text text-anchor=\"middle\" x=\"152\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">NPREMOD</text>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<DependencyGraph with 6 nodes>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunker = Chunker(model= 'resources/chunker.model')\n",
    "print(tree2brackets(chunker.parse(tagged)))\n",
    "\n",
    "parser = DependencyParser(tagger=tagger, lemmatizer=lemmatizer)\n",
    "parser.parse(word_tokenize(normalized_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('او', 'PRO'), ('یک', 'NUM'), ('ماشین', 'N'), ('خرید', 'V'), ('.', 'PUNC')]\n",
      "[('یک', 'NUM'), ('ماشین', 'N'), ('خرید', 'V'), ('.', 'PUNC')]\n"
     ]
    }
   ],
   "source": [
    "tagged = tagger.tag(word_tokenize(normalized_sentence))\n",
    "print(tagged)\n",
    "\n",
    "# Convert Active Voice to Passive Voice\n",
    "# remove 'PRO' from the list of tags\n",
    "tags = [item for item in tagged if item[1] != 'PRO']\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "خرید\n",
      "['خرید']\n"
     ]
    }
   ],
   "source": [
    "# purify the verb\n",
    "verbs = [item[0] for item in tags if item[1] == 'V'][0]\n",
    "print(verbs)\n",
    "verbs = lemmatizer.lemmatize(verbs).split(\"#\")\n",
    "print(verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ماشین خریده شد.\n"
     ]
    }
   ],
   "source": [
    "new_sentence = \"\"\n",
    "# get first 'N' from tags list and add it to new sentence\n",
    "for item in tags:\n",
    "    if item[1] == 'N':\n",
    "        new_sentence += lemmatizer.lemmatize(item[0])\n",
    "        # remote item from tags list\n",
    "        tags.remove(item)\n",
    "        break\n",
    "\n",
    "# get 'P' from tags list and add it to new sentence\n",
    "for item in tags:\n",
    "    if item[1] == 'P':\n",
    "        new_sentence += \" \" + item[0]\n",
    "        # remote item from tags list\n",
    "        tags.remove(item)\n",
    "        break\n",
    "\n",
    "# get second 'N' from tags list and add it to new sentence\n",
    "for item in tags:\n",
    "    if item[1] == 'N':\n",
    "        new_sentence += \" \" + item[0]\n",
    "        # remote item from tags list\n",
    "        tags.remove(item)\n",
    "        break\n",
    "\n",
    "new_sentence = new_sentence + \" \" + verbs[0] + \"ه\" + \" \" + \"شد.\"\n",
    "print(new_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
